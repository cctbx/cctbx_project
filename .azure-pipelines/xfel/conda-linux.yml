# Script for building CCTBX
# linux image descriptions
# https://github.com/actions/virtual-environments/blob/master/images/linux/Ubuntu1804-README.md
#
# Parameters:
#   distribution: centos, ubuntu
#   version: [6, 10]
#   modules: <modules artifact name>
#   template: <build template file>
#   prefix: <build artifact prefix>

jobs:
- job: ${{ format('{0}{1}_{2}', parameters.prefix, parameters.distribution, join('_', parameters.version) ) }}
  pool:
    vmImage: ubuntu-20.04
  timeoutInMinutes: 180
  strategy:
    maxParallel: 2
    matrix:
      python3.11:
        CONDA: Linux
        OS: linux
        PYTHON_VERSION: py311
        PYTHON_FULL_VERSION: 3.11
        MODULES: ${{ parameters.modules }}

  container:
    image: ${{ parameters.distribution }}:${{ join('.', parameters.version) }}
    options: --name ci-container --privileged
    volumes:
      - /usr/bin/docker:/tmp/docker:ro
      - /usr:/tmp/host_usr:rw
      - /opt:/tmp/host_opt:rw

  variables:
    artifact_name: ${{ parameters.prefix }}${{ parameters.distribution }}_${{ join('.', parameters.version) }}_$(PYTHON_VERSION)
    day: Sunday

  steps:
  - script: |
      day=`date +%A`
      echo $(day)
      echo "##vso[task.setVariable variable=day]$day"
    displayName: Get day of week

  - script: echo $(day)
    displayName: Check day of week

  # https://github.com/ApexAI/performance_test/blob/master/azure-pipelines.yml#L9-L17

  # centos setup
  # https://serverfault.com/questions/1161816/mirrorlist-centos-org-no-longer-resolve
  - script: |
      set -xe
      /tmp/docker exec -t -u 0 ci-container \
      sh -c "sed -i s/mirror.centos.org/vault.centos.org/g /etc/yum.repos.d/*.repo"
      /tmp/docker exec -t -u 0 ci-container \
      sh -c "sed -i s/^#.*baseurl=http/baseurl=http/g /etc/yum.repos.d/*.repo"
      /tmp/docker exec -t -u 0 ci-container \
      sh -c "sed -i s/^mirrorlist=http/#mirrorlist=http/g /etc/yum.repos.d/*.repo"
    displayName: Modify yum repositories for CentOS 7
    condition: eq('${{ parameters.distribution }}', 'centos')

  - script: |
      /tmp/docker exec -t -u 0 ci-container \
      sh -c "yum install -y sudo"
    displayName: Set up sudo for CentOS and Rocky Linux
    condition: or(eq('${{ parameters.distribution }}', 'centos'),
                  eq('${{ parameters.distribution }}', 'rockylinux'))

  - script: |
      sudo yum groupinstall -y 'Development Tools'
      sudo yum install -y mesa-libGLU-devel mesa-libGL-devel tcsh
    displayName: Install dependencies for CentOS
    condition: eq('${{ parameters.distribution }}', 'centos')

  - script: |
      sudo yum install -y ucx
    displayName: Add libucx for Rocky Linux
    condition: eq('${{ parameters.distribution }}', 'rockylinux')

  - bash: |
      echo "##vso[task.setvariable variable=LC_ALL]C.utf8"
    displayName: Setup locale for CentOS 8
    condition: or(eq('${{ parameters.version[0] }}', 8),
                  eq('${{ parameters.version[0] }}', 9))

  # https://lists.openhpc.community/g/users/topic/openmpi_and_shared_memory/16489081?p=,,,20,0,0,0::recentpostdate%2Fsticky,,,20,2,0,16489081
  - script: |
      sudo sysctl -w kernel.yama.ptrace_scope=0
    displayName: Hide OpenMPI warning
    condition: eq('${{ parameters.distribution }}', 'centos')

  # ubuntu setup
  - script: |
      /tmp/docker exec -t -u 0 ci-container \
      sh -c "apt-get update && DEBIAN_FRONTEND=noninteractive apt-get -o Dpkg::Options::="--force-confold" -y install sudo"
    displayName: Set up sudo for Ubuntu
    condition: eq('${{ parameters.distribution }}', 'ubuntu')

  - script: |
      sudo apt-get install -y build-essential curl git libgl1-mesa-dev libglu1-mesa-dev locales subversion
      sudo locale-gen en_US.UTF-8
      sudo update-locale
    displayName: Install dependencies for Ubuntu
    condition: eq('${{ parameters.distribution }}', 'ubuntu')

  - script: |
      echo $(System.CollectionId)
      echo $(System.CollectionUri)
      echo $(System.TeamProject)
      echo $(System.TeamProjectId)
      echo $(System.DefinitionID)
    displayName: Show System variables

  - script: |
      sudo mkdir -p /tmp/empty_dir
      sudo rsync --stats -a --delete /tmp/empty_dir/ /tmp/host_opt/hostedtoolcache
      for d in \
          lib/jvm \
          local/.ghcup \
          local/lib/android \
          local/share/powershell \
          share/dotnet \
          share/swift \
        ; do
        echo Deleting $d
        sudo rsync --stats -a --delete /tmp/empty_dir/ /tmp/host_usr/$d
      done
      df -h
    displayName: Clean up host image
    continueOnError: true

  # download daily cached build directory for builds
  # always do builds from scratch for "Update build cache" on Saturday night (Pacific)
  # always do builds from scratch for "Weekly" pipeline
  - task: DownloadPipelineArtifact@2
    inputs:
      source: 'specific'
      project: '$(resources.pipeline.build_cache.projectID)'
      pipeline: '$(resources.pipeline.build_cache.pipelineID)'
      allowPartiallySucceededBuilds: true
      allowFailedBuilds: true
      artifact: '$(artifact_name)'
      path: $(Pipeline.Workspace)
    displayName: Download cached build
    condition: >
      and(or(and(eq(variables['Build.DefinitionName'], 'Update build cache'),
                 ne(variables['day'], 'Sunday')),
             eq(variables['Build.DefinitionName'], 'CI'),
             eq(variables['Build.DefinitionName'], 'CI branch'),
             eq(variables['Build.DefinitionName'], 'XFEL CI'),
             eq(variables['Build.DefinitionName'], 'XFEL CI branch'),
             eq(variables['Build.DefinitionName'], 'Full')),
          ne(variables['SKIP_CACHED_BUILD'], 'true'))
    continueOnError: true

  - script: |
      cd $(Pipeline.Workspace)
      tar -xf build.tar
      rm build.tar
    displayName: Extract build tarball
    condition: >
      and(or(and(eq(variables['Build.DefinitionName'], 'Update build cache'),
                 ne(variables['day'], 'Sunday')),
             eq(variables['Build.DefinitionName'], 'CI'),
             eq(variables['Build.DefinitionName'], 'CI branch'),
             eq(variables['Build.DefinitionName'], 'XFEL CI'),
             eq(variables['Build.DefinitionName'], 'XFEL CI branch'),
             eq(variables['Build.DefinitionName'], 'Full')),
          ne(variables['SKIP_CACHED_BUILD'], 'true'))
    continueOnError: true
    failOnStderr: false

  # build
  - template: ${{ parameters.template }}
    parameters:
      distribution: ${{ parameters.distribution }}
      version: ${{ parameters.version }}

  # preserve permissions
  - script: |
      cd $(Pipeline.Workspace)
      rm -fr tests
      tar -chf build.tar build
    displayName: Build tarball
    condition: >
      and(eq(variables['Build.DefinitionName'], 'Update build cache'),
          or(eq(variables['Build.Reason'], 'Schedule'),
             eq(variables['Build.Reason'], 'Manual')),
          eq(variables['System.StageAttempt'], 1),
          eq('${{ parameters.modules }}', 'xfel_modules'))
    continueOnError: true

  # cache build directory every week for regular optimization build
  - publish: $(Pipeline.Workspace)/build.tar
    artifact: $(artifact_name)
    condition: >
      and(eq(variables['Build.DefinitionName'], 'Update build cache'),
          or(eq(variables['Build.Reason'], 'Schedule'),
             eq(variables['Build.Reason'], 'Manual')),
          eq(variables['System.StageAttempt'], 1),
          eq('${{ parameters.modules }}', 'xfel_modules'))
    continueOnError: true

  # check disk space at the end
  - script: df -h
    displayName: Check disk space
